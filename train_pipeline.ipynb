{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '6'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CtTauVJNsP3",
    "outputId": "5d096784-87a7-47af-e599-d0cb5957e38e"
   },
   "outputs": [],
   "source": [
    "from MAESeqModule.MAESeq_utils import dataloader,get_dict, seq_data_to_onehot\n",
    "import numpy as np\n",
    "DICT_EXIST = True\n",
    "DICT_PATH_CHAR2INT = 'dict/char2int.npy'\n",
    "DICT_PATH_INT2CHAR = 'dict/int2char.npy'\n",
    "DATA_PATH = 'dataset/scop_fa_represeq_lib_latest.fa'\n",
    "\n",
    "seq_list, max_len = dataloader(\n",
    "    file= DATA_PATH,\n",
    "    len_data=35000, max_len_percintile=75)\n",
    "max_len = 300 # 在这里统一一下\n",
    "\n",
    "if DICT_EXIST:\n",
    "    dict_char2int = np.load(DICT_PATH_CHAR2INT, allow_pickle = True).item()\n",
    "    dict_int2char = np.load(DICT_PATH_INT2CHAR,allow_pickle = True).item()\n",
    "else:\n",
    "    dict_char2int, dict_int2char = get_dict(seq_list)\n",
    "    np.save(DICT_PATH_CHAR2INT, dict_char2int)\n",
    "    np.save(DICT_PATH_INT2CHAR, dict_int2char)\n",
    "\n",
    "onehot_data = seq_data_to_onehot(seq_list,dict_char2int,max_len)\n",
    "dimension = len(dict_char2int)\n",
    "\n",
    "print(\"Length of seq is {}\".format(max_len))\n",
    "print(\"Dimension is {}\".format(dimension))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGlKzV-DNsQC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "onehot_train, onehot_val,onehot_test =np.split(onehot_data,[\n",
    "        int(len(onehot_data)*0.8), \n",
    "        int(len(onehot_data)*0.95)])\n",
    "print(onehot_train.shape)\n",
    "print(onehot_val.shape)\n",
    "print(onehot_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate = 1e-3,\n",
    "    decay_steps = 438*2,\n",
    "    decay_rate = 0.93,\n",
    "    staircase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_T6-oVwszTwV"
   },
   "outputs": [],
   "source": [
    "from MAESeqModule.MAESeq_utils import mask_onehot_matrix\n",
    "MASK_RATE = 0.1\n",
    "onehot_train_mask = mask_onehot_matrix(onehot_train,MASK_RATE)\n",
    "onehot_val_mask = mask_onehot_matrix(onehot_test,MASK_RATE)\n",
    "onehot_test_mask = mask_onehot_matrix(onehot_test,MASK_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JNFsOSlP77_n"
   },
   "outputs": [],
   "source": [
    "from keras import losses,optimizers\n",
    "from  MAESeqModule.MAESeq_model  import AutoencoderGRU,my_loss_entropy,ReconstructRateVaried\n",
    "autoencoder = AutoencoderGRU(latent_dim=512, encoder_shapes=(max_len, dimension))\n",
    "# autoencoder.compile(optimizer='adam', loss= losses.categorical_crossentropy )\n",
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler), \n",
    "                    loss = my_loss_entropy, \n",
    "                    metrics = [ReconstructRateVaried])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XA-W8dl2XzeK",
    "outputId": "9b0bc064-d0e8-4b13-d949-f710e1321a09",
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "history = autoencoder.fit(onehot_train_mask, onehot_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(onehot_test_mask, onehot_test)) \n",
    "autoencoder.save('trained_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "res_data_dict = {\n",
    "        'Loss':history.history['loss'],\n",
    "        'ValLoss':history.history['val_loss'],\n",
    "        'ReconstructRate':history.history['ReconstructRateVaried'],\n",
    "        'ValReconstructRate':history.history['val_ReconstructRateVaried']\n",
    "    }\n",
    "res_data = pd.DataFrame(res_data_dict)\n",
    "res_data.to_csv('res/res_data.csv')\n",
    "\n",
    "loss_res = history.history['loss']\n",
    "val_loss_res = history.history['val_loss']\n",
    "reconstructRate = history.history['ReconstructRateVaried']\n",
    "reconstructRateVal = history.history['val_ReconstructRateVaried']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "cUC22mxifcL2",
    "outputId": "5e6a3e61-c115-42a2-c795-15d16d9daa4c"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_res,'r', label='loss')\n",
    "plt.plot(val_loss_res, label = 'val_loss')\n",
    "plt.legend()\n",
    "plt.savefig('res/res_loss.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(reconstructRate,'r', label='reconstructRate')\n",
    "plt.plot(reconstructRateVal, label = 'val_reconstructRate')\n",
    "plt.legend()\n",
    "plt.savefig('res/res_reconstruct_rate.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = autoencoder.predict(onehot_test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r-rH6bepyFo9",
    "outputId": "65664700-0797-42b2-851e-48e2a5bfee8d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from MAESeqModule.MAESeq_utils import onehot_to_seq\n",
    "print(ReconstructRateVaried(test, onehot_test,dict_int2char))\n",
    "for i in range(10):\n",
    "  print('原先')\n",
    "  print(onehot_to_seq(onehot_test[i],dict_int2char))\n",
    "  print('预测')\n",
    "  print(onehot_to_seq(test[i],dict_int2char))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.9.13 ('maeseq': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b711737b996ed101b0af1d9f34b3f51b08a754080d2c2215c530ee3225577c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
