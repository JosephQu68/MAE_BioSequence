{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(True) # Enable XLA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CtTauVJNsP3",
    "outputId": "5d096784-87a7-47af-e599-d0cb5957e38e"
   },
   "outputs": [],
   "source": [
    "from MAESeqModule.MAESeq_utils import dataloader,get_dict, seq_data_to_onehot\n",
    "import numpy as np\n",
    "DICT_EXIST = True\n",
    "DATASET_EXIST = True\n",
    "DICT_PATH_CHAR2INT = 'dict/char2int.npy'\n",
    "DICT_PATH_INT2CHAR = 'dict/int2char.npy'\n",
    "DATA_PATH = 'dataset/scop_fa_represeq_lib_latest.fa'\n",
    "DATA_NPY_PATH = '/geniusland/home/qufuchuan/dataset/uniref90_min20_max300_num120k.npy'\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 500\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "\n",
    "if DATASET_EXIST:\n",
    "    seq_list = np.load(DATA_NPY_PATH)\n",
    "else:\n",
    "    seq_list, max_len = dataloader(\n",
    "    file= DATA_PATH,\n",
    "    len_data=35000, max_len_percintile=75)\n",
    "\n",
    "max_len = 300 # 在这里统一一下\n",
    "\n",
    "if DICT_EXIST:\n",
    "    dict_char2int = np.load(DICT_PATH_CHAR2INT, allow_pickle = True).item()\n",
    "    dict_int2char = np.load(DICT_PATH_INT2CHAR,allow_pickle = True).item()\n",
    "else:\n",
    "    dict_char2int, dict_int2char = get_dict(seq_list)\n",
    "    np.save(DICT_PATH_CHAR2INT, dict_char2int)\n",
    "    np.save(DICT_PATH_INT2CHAR, dict_int2char)\n",
    "\n",
    "onehot_data = seq_data_to_onehot(seq_list,dict_char2int,max_len)\n",
    "dimension = len(dict_char2int)\n",
    "\n",
    "print(\"Length of seq is {}\".format(max_len))\n",
    "print(\"Dimension is {}\".format(dimension))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGlKzV-DNsQC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "onehot_train, onehot_val,onehot_test =np.split(onehot_data,[\n",
    "        int(len(onehot_data)*0.8), \n",
    "        int(len(onehot_data)*0.99)])\n",
    "print(onehot_train.shape)\n",
    "print(onehot_val.shape)\n",
    "print(onehot_test.shape)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MAESeqModule.MAESeq_utils import mask_onehot_matrix,evaluate_per_mask_rate,extract_history\n",
    "\n",
    "onehot_train_mask = mask_onehot_matrix(onehot_train,0.15)\n",
    "onehot_val_mask = mask_onehot_matrix(onehot_val,0.15)\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((onehot_train_mask, onehot_train))\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((onehot_val_mask, onehot_val))\n",
    "# val_dataset = val_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from MAESeqModule.MAESeq_scheduler import WarmUpCosine\n",
    "\n",
    "total_steps = int((len(onehot_train) / BATCH_SIZE) * EPOCHS)\n",
    "warmup_epoch_percentage = 0.10\n",
    "warmup_steps = int(total_steps * warmup_epoch_percentage)\n",
    "warmup_cosine_lr_scheduler = WarmUpCosine(\n",
    "    learning_rate_base=LEARNING_RATE,\n",
    "    total_steps=total_steps,\n",
    "    warmup_learning_rate=0.0,\n",
    "    warmup_steps=warmup_steps,\n",
    ")\n",
    "\n",
    "lr_scheduler = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate = 1e-3,\n",
    "    decay_steps = int(2 * len(onehot_train)/BATCH_SIZE),\n",
    "    decay_rate = 0.93,\n",
    "    staircase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses,optimizers,backend\n",
    "from  MAESeqModule.MAESeq_model  import AutoencoderGRU_withMaskLoss,my_loss_entropy,ReconstructRateVaried\n",
    "from MAESeqModule.MAESeq_utils import mask_onehot_matrix,evaluate_per_mask_rate,extract_history\n",
    "\n",
    "\n",
    "autoencoder = AutoencoderGRU_withMaskLoss(latent_dim=512, encoder_shapes=(max_len, dimension))\n",
    "\n",
    "MP_optimizer = tf.keras.optimizers.Adam(learning_rate=warmup_cosine_lr_scheduler)\n",
    "MP_optimizer = mixed_precision.LossScaleOptimizer(MP_optimizer)\n",
    "          \n",
    "autoencoder.compile(optimizer=MP_optimizer, \n",
    "                    loss = my_loss_entropy, \n",
    "                    metrics = [ReconstructRateVaried])\n",
    "    \n",
    "history = autoencoder.fit(onehot_train_mask,onehot_train,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    shuffle=True,\n",
    "                    validation_data= [onehot_val_mask,onehot_val],\n",
    "                    callbacks=tf.keras.callbacks.ReduceLROnPlateau(min_delta = 0.0003))\n",
    "hist_data = extract_history(history)\n",
    "hist_data.to_csv('training_history.csv')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8b711737b996ed101b0af1d9f34b3f51b08a754080d2c2215c530ee3225577c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
